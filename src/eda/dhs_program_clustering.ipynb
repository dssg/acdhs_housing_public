{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports and db connection setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import kmeans_plusplus\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn import metrics\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get credentials from environment variables\n",
    "user = os.getenv('PGUSER')\n",
    "password = os.getenv('PGPASSWORD')\n",
    "host = os.getenv('PGHOST')\n",
    "port = os.getenv('PGPORT')\n",
    "database = os.getenv('PGDATABASE')\n",
    "\n",
    "# configure connection to postgres\n",
    "engine = create_engine(\"postgresql://{}:{}@{}:{}/{}\".format(user, password, host, port, database))\n",
    "\n",
    "# open a connect\n",
    "db_conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"select * from modelling.acdhs_program_participation_and_evictions8;\", db_conn)\n",
    "#df = db_conn.execute(sql_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cluster the different programs offered by DHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features to include:\n",
    "- all starting with \"p_\"\n",
    "- expect homelessness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df.columns if \"p_\" in col and col not in [\"p_263\", \"p_29\", \"p_32\", \"p_33\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum() # no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA with one/two/three principal components\n",
    "pca_1d = PCA(n_components=1)\n",
    "pca_2d = PCA(n_components=2)\n",
    "pca_3d = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps = []\n",
    "cumulative_variance = []\n",
    "#for n_comp in range(1, X.shape[1]):\n",
    "#for n_comp in range(1, 30):\n",
    "for n_comp in [1,2,5,10,15,25, 50, 75, 100, 125, 150]:\n",
    "    n_comps.append(n_comp)\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    pca_result = pca.fit_transform(X)\n",
    "    print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "    print('Cumulative variance explained by {} principal components: {:.2%}'.format(n_comp, np.sum(pca.explained_variance_ratio_)))\n",
    "    cumulative_variance.append(np.sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_comps, cumulative_variance)\n",
    "plt.xlabel(\"number of components\")\n",
    "plt.ylabel(\"Cumulative variance explained by components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding important features with the help of PCA\n",
    "pca_2d = PCA(n_components=2)\n",
    "pca_result = pca_2d.fit_transform(X)\n",
    "dataset_pca = pd.DataFrame(abs(pca_2d.components_), columns=X.columns, index=['PC_1', 'PC_2'])\n",
    "print('\\n\\n', dataset_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using the elbow method\n",
    "\n",
    "choose number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distortion for a range of number of cluster\n",
    "distortions = []\n",
    "#nr_of_clusters = [1,2,3,4,5]\n",
    "nr_of_clusters = [1,2,3,4,5,7,9,11,15,20,25,30,35,40,50,75]\n",
    "for i in nr_of_clusters:\n",
    "    print(i, \"clusters\")\n",
    "    km = KMeans(\n",
    "        n_clusters=i, init='k-means++',\n",
    "        n_init=10, max_iter=100,\n",
    "        tol=1e-04, random_state=0\n",
    "    )\n",
    "    km.fit(X)\n",
    "    distortions.append(km.inertia_)\n",
    "\n",
    "# plot\n",
    "plt.plot(nr_of_clusters, distortions, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimum_num_clusters = best_grid['n_clusters']\n",
    "optimum_num_clusters = 7\n",
    "\n",
    "# fitting KMeans\n",
    "kmeans = KMeans(n_clusters=optimum_num_clusters)\n",
    "kmeans.fit(X)\n",
    "centroids = kmeans.cluster_centers_\n",
    "centroids_pca = pca_2d.transform(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizing_results(pca_result, label, centroids_pca):\n",
    "    \"\"\" Visualizing the clusters\n",
    "    :param pca_result: PCA applied data\n",
    "    :param label: K Means labels\n",
    "    :param centroids_pca: PCA format K Means centroids\n",
    "    \"\"\"\n",
    "    x = pca_result[:, 0]\n",
    "    y = pca_result[:, 1]\n",
    "\n",
    "    plt.scatter(x, y, c=label, alpha=0.1, s=10)  # plot different colors per cluster\n",
    "    plt.title('DHS program participation')\n",
    "    plt.xlabel('PCA 1')\n",
    "    plt.ylabel('PCA 2')\n",
    "\n",
    "    plt.scatter(centroids_pca[:, 0], centroids_pca[:, 1], marker='X', s=200, linewidths=1.5,\n",
    "                color='red', edgecolors=\"black\", lw=1.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizing_results(pca_result, kmeans.labels_, centroids_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cluster centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all program names\n",
    "program_names = pd.read_sql(\"select program_key, program_name from lookup.program_feed pf ;\", db_conn)\n",
    "program_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"kmeans has seen\", kmeans.n_features_in_, \"during fit.\")\n",
    "centroid_weights = zip(range(optimum_num_clusters), centroids)\n",
    "for cluster_nr, c in centroid_weights:\n",
    "    print(\"Cluster:\", cluster_nr)\n",
    "    #sorted_zip = sorted(cluster_and_programs, key = lambda x: x[1])\n",
    "    cluster_and_programs_sorted = sorted(list(zip(kmeans.feature_names_in_,c)), key = lambda x: x[1], reverse=True)\n",
    "    counter = 0\n",
    "    for feature, weights in cluster_and_programs_sorted:\n",
    "        #program_name = program_names[program_names[\"program_key\"]==feature.lstrip(\"p_\")][\"program_name\"][0]\n",
    "        #print(program_names[program_names[\"program_key\"]==1][\"program_name\"][0])\n",
    "        #print(\"a\", feature.lstrip(\"p_\"))\n",
    "        #print(program_names[program_names[\"program_key\"]==int(feature.lstrip(\"p_\"))])\n",
    "        program_name = list(program_names[program_names[\"program_key\"]==int(feature.lstrip(\"p_\"))][\"program_name\"])[0]\n",
    "        print(\"\\t\", program_name, feature, weights)\n",
    "        counter += 1\n",
    "        if counter >30:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find which cluster each data-point belongs to\n",
    "clusters = kmeans.predict(X)\n",
    "#Add the cluster vector to our DataFrame, X\n",
    "#X[\"Cluster\"] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyse the clusters and check share of homeless individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clustered = X.copy(deep=True)\n",
    "X_clustered[\"cluster\"] = kmeans.predict(X)\n",
    "X_clustered[\"cluster_dist\"] = [np.min(i) for i in kmeans.transform(X)]\n",
    "X_clustered[\"homeless\"] = df['p_263'].replace([0,1],[\"No\", \"Yes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(X_clustered[X_clustered[\"cluster\"]==0].drop(columns=['cluster', 'cluster_dist', 'homeless']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs_grouped_by_hl = X_clustered[X_clustered[\"cluster\"]==0].drop(columns=['cluster', 'cluster_dist']).groupby(\"homeless\").sum().reset_index()\n",
    "px.bar(programs_grouped_by_hl.melt(id_vars=[\"homeless\"]),x=\"variable\", y=\"value\", color=\"homeless\", title = \"Cluster 0 (n=\" + str(X_clustered[X_clustered[\"cluster\"]==0].shape[0]) + \" / n_homeless=\" + str(X_clustered[(X_clustered[\"cluster\"]==0) & (X_clustered[\"homeless\"]==\"Yes\")].shape[0]) + \" / n_program_participation = \" + str(sum(X_clustered[X_clustered[\"cluster\"]==0].drop(columns=['cluster', 'cluster_dist', 'homeless']).sum())) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs_grouped_by_hl = X_clustered[X_clustered[\"cluster\"]==1].drop(columns=['cluster', 'cluster_dist']).groupby(\"homeless\").sum().reset_index()\n",
    "px.bar(programs_grouped_by_hl.melt(id_vars=[\"homeless\"]),x=\"variable\", y=\"value\", color=\"homeless\", title = \"Cluster 1 (n=\" + str(X_clustered[X_clustered[\"cluster\"]==1].shape[0]) + \" / n_homeless=\" + str(X_clustered[(X_clustered[\"cluster\"]==1) & (X_clustered[\"homeless\"]==\"Yes\")].shape[0]) + \" / n_program_participation = \" + str(sum(X_clustered[X_clustered[\"cluster\"]==1].drop(columns=['cluster', 'cluster_dist', 'homeless']).sum())) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs_grouped_by_hl = X_clustered[X_clustered[\"cluster\"]==2].drop(columns=['cluster', 'cluster_dist']).groupby(\"homeless\").sum().reset_index()\n",
    "px.bar(programs_grouped_by_hl.melt(id_vars=[\"homeless\"]),x=\"variable\", y=\"value\", color=\"homeless\", title = \"Cluster 2 (n=\" + str(X_clustered[X_clustered[\"cluster\"]==2].shape[0]) + \" / n_homeless=\" + str(X_clustered[(X_clustered[\"cluster\"]==2) & (X_clustered[\"homeless\"]==\"Yes\")].shape[0]) + \" / n_program_participation = \" + str(sum(X_clustered[X_clustered[\"cluster\"]==2].drop(columns=['cluster', 'cluster_dist', 'homeless']).sum())) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs_grouped_by_hl = X_clustered[X_clustered[\"cluster\"]==3].drop(columns=['cluster', 'cluster_dist']).groupby(\"homeless\").sum().reset_index()\n",
    "px.bar(programs_grouped_by_hl.melt(id_vars=[\"homeless\"]),x=\"variable\", y=\"value\", color=\"homeless\", title = \"Cluster 3 (n=\" + str(X_clustered[X_clustered[\"cluster\"]==3].shape[0]) + \" / n_homeless=\" + str(X_clustered[(X_clustered[\"cluster\"]==3) & (X_clustered[\"homeless\"]==\"Yes\")].shape[0]) + \" / n_program_participation = \" + str(sum(X_clustered[X_clustered[\"cluster\"]==3].drop(columns=['cluster', 'cluster_dist', 'homeless']).sum())) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs_grouped_by_hl = X_clustered[X_clustered[\"cluster\"]==4].drop(columns=['cluster', 'cluster_dist']).groupby(\"homeless\").sum().reset_index()\n",
    "px.bar(programs_grouped_by_hl.melt(id_vars=[\"homeless\"]),x=\"variable\", y=\"value\", color=\"homeless\", title = \"Cluster 4 (n=\" + str(X_clustered[X_clustered[\"cluster\"]==4].shape[0]) + \" / n_homeless=\" + str(X_clustered[(X_clustered[\"cluster\"]==4) & (X_clustered[\"homeless\"]==\"Yes\")].shape[0]) + \" / n_program_participation = \" + str(sum(X_clustered[X_clustered[\"cluster\"]==4].drop(columns=['cluster', 'cluster_dist', 'homeless']).sum())) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs_grouped_by_hl = X_clustered[X_clustered[\"cluster\"]==5].drop(columns=['cluster', 'cluster_dist']).groupby(\"homeless\").sum().reset_index()\n",
    "px.bar(programs_grouped_by_hl.melt(id_vars=[\"homeless\"]),x=\"variable\", y=\"value\", color=\"homeless\", title = \"Cluster 5 (n=\" + str(X_clustered[X_clustered[\"cluster\"]==5].shape[0]) + \" / n_homeless=\" + str(X_clustered[(X_clustered[\"cluster\"]==5) & (X_clustered[\"homeless\"]==\"Yes\")].shape[0]) + \" / n_program_participation = \" + str(sum(X_clustered[X_clustered[\"cluster\"]==5].drop(columns=['cluster', 'cluster_dist', 'homeless']).sum())) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs_grouped_by_hl = X_clustered[X_clustered[\"cluster\"]==6].drop(columns=['cluster', 'cluster_dist']).groupby(\"homeless\").sum().reset_index()\n",
    "px.bar(programs_grouped_by_hl.melt(id_vars=[\"homeless\"]),x=\"variable\", y=\"value\", color=\"homeless\", title = \"Cluster 6 (n=\" + str(X_clustered[X_clustered[\"cluster\"]==6].shape[0]) + \" / n_homeless=\" + str(X_clustered[(X_clustered[\"cluster\"]==6) & (X_clustered[\"homeless\"]==\"Yes\")].shape[0]) + \" / n_program_participation = \" + str(sum(X_clustered[X_clustered[\"cluster\"]==6].drop(columns=['cluster', 'cluster_dist', 'homeless']).sum())) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# individuals closest to each cluster centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_nr in range(optimum_num_clusters):\n",
    "    print(\"Cluster:\", cluster_nr)\n",
    "    closest_individuals = X_clustered[X_clustered[\"cluster\"] == cluster_nr][\"cluster_dist\"].nsmallest(20)\n",
    "    closest_individuals_homeless = X_clustered[(X_clustered[\"cluster\"] == cluster_nr) & (X_clustered[\"homeless\"] == \"Yes\")][\"cluster_dist\"].nsmallest(20)\n",
    "    for i, value in closest_individuals.iteritems():\n",
    "        print(\"\\t\\t client_hash:\", df.loc[i, \"client_hash\"], \"cluster_distance:\", value)\n",
    "    print(\"\\t closest homeless individuals:\")\n",
    "    for i, value in closest_individuals_homeless.iteritems():\n",
    "        print(\"\\t\\t client_hash:\", df.loc[i, \"client_hash\"], \"cluster_distance:\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "43369cd228aa974b7613bf148553ec85c0ec3106e12bb1b8e6fc9fdce8b41479"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
